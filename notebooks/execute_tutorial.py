#!/usr/bin/env python3
"""Execute notebook tutorial cells sequentially."""

import sys
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json

# Set display options
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', 50)

# Set plotting style (compatible with different matplotlib versions)
try:
    plt.style.use('seaborn-v0_8-darkgrid')
except OSError:
    try:
        plt.style.use('seaborn-darkgrid')
    except OSError:
        plt.style.use('default')
sns.set_palette("husl")

print("=" * 70)
print("ğŸš€ æ‰§è¡Œ Notebook æ•™ç¨‹ - å®Œæ•´æµç¨‹")
print("=" * 70)

# Cell 1: Import libraries (already done above)
print("\nâœ… Cell 1: åº“å¯¼å…¥æˆåŠŸï¼")
print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"ğŸ Python ç‰ˆæœ¬: {sys.version.split()[0]}")

# Cell 3: Load raw data
print("\n" + "=" * 70)
print("ğŸ“‚ Cell 3: åŠ è½½åŸå§‹æ•°æ®")
print("=" * 70)

from src.data.loaders import DataLoader

data_path = project_root / "data/raw/frost-risk-forecast-challenge/cimis_all_stations.csv.gz"

if not data_path.exists():
    print(f"âŒ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {data_path}")
    sys.exit(1)

print(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")
loader = DataLoader()
df_raw = loader.load_raw_data(data_path)
print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼")
print(f"   å½¢çŠ¶: {df_raw.shape}")
print(f"   åˆ—æ•°: {len(df_raw.columns)}")
print(f"   æ—¶é—´èŒƒå›´: {df_raw['Date'].min()} åˆ° {df_raw['Date'].max()}")
print(f"   ç«™ç‚¹æ•°: {df_raw['Stn Id'].nunique()}")

# Cell 9: Configure data pipeline
print("\n" + "=" * 70)
print("âš™ï¸  Cell 9: é…ç½®æ•°æ®å¤„ç†ç®¡é“")
print("=" * 70)

from src.data import DataPipeline

config = {
    "cleaning": {
        "config_path": str(project_root / "config/data_cleaning.yaml")
    },
    "labels": {
        "threshold": 0.0
    },
    "feature_engineering": {
        "enabled": True,
        "feature_selection": {
            "method": "top_k",
            "top_k": 175
        }
    },
    "random_state": 42
}

pipeline = DataPipeline(config=config)
print("âœ… æ•°æ®ç®¡é“åˆ›å»ºæˆåŠŸï¼")

# Cell 10: Process data
print("\n" + "=" * 70)
print("ğŸ”„ Cell 10: å¤„ç†æ•°æ®ï¼ˆä½¿ç”¨é‡‡æ ·ï¼‰")
print("=" * 70)

print("   âš ï¸  æ³¨æ„ï¼šä¸ºäº†æ¼”ç¤ºé€Ÿåº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨é‡‡æ ·æ•°æ®ï¼ˆ10ä¸‡è¡Œï¼‰")
print("   ğŸ’¡ å®é™…è®­ç»ƒæ—¶å¯ä»¥ç§»é™¤ sample_size å‚æ•°ä½¿ç”¨å…¨éƒ¨æ•°æ®")

dataset_bundle = pipeline.run(
    data_path=data_path,
    horizons=[12],
    use_feature_engineering=True,
    sample_size=100000,
    random_state=42
)

df_processed = dataset_bundle.data
print(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼")
print(f"   å¤„ç†åå½¢çŠ¶: {df_processed.shape}")
print(f"   ç‰¹å¾æ•°: {len(dataset_bundle.feature_columns)}")
print(f"   æ ‡ç­¾æ•°: {len(dataset_bundle.label_columns)}")

# Cell 12: Prepare training data
print("\n" + "=" * 70)
print("ğŸ“Š Cell 12: å‡†å¤‡è®­ç»ƒæ•°æ®")
print("=" * 70)

from src.training.data_preparation import prepare_features_and_targets
from src.evaluation.validators import CrossValidator
from src.models.registry import get_model_class

print("ğŸ“Š æ‰§è¡Œæ—¶é—´åºåˆ—åˆ†å‰²...")
train_df, val_df, test_df = CrossValidator.time_split(
    df=df_processed,
    train_ratio=0.7,
    val_ratio=0.15,
    date_col="Date"
)

print(f"   è®­ç»ƒé›†: {len(train_df)} æ ·æœ¬")
print(f"   éªŒè¯é›†: {len(val_df)} æ ·æœ¬")
print(f"   æµ‹è¯•é›†: {len(test_df)} æ ·æœ¬")

print("\nğŸ”§ å‡†å¤‡è®­ç»ƒé›†ç‰¹å¾å’Œæ ‡ç­¾...")
X_train, y_frost_train, y_temp_train = prepare_features_and_targets(
    df=train_df,
    horizon=12,
    track="top175_features"
)

print("ğŸ”§ å‡†å¤‡éªŒè¯é›†ç‰¹å¾å’Œæ ‡ç­¾...")
X_val, y_frost_val, y_temp_val = prepare_features_and_targets(
    df=val_df,
    horizon=12,
    track="top175_features"
)

print("ğŸ”§ å‡†å¤‡æµ‹è¯•é›†ç‰¹å¾å’Œæ ‡ç­¾...")
X_test, y_frost_test, y_temp_test = prepare_features_and_targets(
    df=test_df,
    horizon=12,
    track="top175_features"
)

print("\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬, {X_train.shape[1]} ç‰¹å¾")
print(f"   éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬")
print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
print(f"   éœœå†»äº‹ä»¶ (è®­ç»ƒé›†): {y_frost_train.sum()} ({y_frost_train.mean()*100:.2f}%)")
print(f"   å¹³å‡æ¸©åº¦ (è®­ç»ƒé›†): {y_temp_train.mean():.2f}Â°C")

# Cell 13: Train models
print("\n" + "=" * 70)
print("ğŸ¤– Cell 13: è®­ç»ƒæ¨¡å‹")
print("=" * 70)

ModelClass = get_model_class('lightgbm')

print("ğŸ¤– è®­ç»ƒéœœå†»åˆ†ç±»æ¨¡å‹ (LightGBM)...")
frost_model = ModelClass(
    config={
        'task_type': 'classification',
        'model_params': {
            'objective': 'binary',
            'metric': 'binary_logloss',
            'n_estimators': 100,
            'learning_rate': 0.05,
            'max_depth': 7,
            'random_state': 42,
            'verbosity': -1
        }
    }
)

frost_model.fit(
    X=X_train,
    y=y_frost_train,
    eval_set=[(X_val, y_frost_val)]
)
print("âœ… åˆ†ç±»æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

print("ğŸ¤– è®­ç»ƒæ¸©åº¦å›å½’æ¨¡å‹ (LightGBM)...")
temp_model = ModelClass(
    config={
        'task_type': 'regression',
        'model_params': {
            'objective': 'regression',
            'metric': 'rmse',
            'n_estimators': 100,
            'learning_rate': 0.05,
            'max_depth': 7,
            'random_state': 42,
            'verbosity': -1
        }
    }
)

temp_model.fit(
    X=X_train,
    y=y_temp_train,
    eval_set=[(X_val, y_temp_val)]
)
print("âœ… å›å½’æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

# Cell 15: Evaluate classification model
print("\n" + "=" * 70)
print("ğŸ“Š Cell 15: è¯„ä¼°åˆ†ç±»æ¨¡å‹")
print("=" * 70)

from src.evaluation.metrics import MetricsCalculator

y_frost_pred = frost_model.predict(X_test)
y_frost_proba = frost_model.predict_proba(X_test)

metrics_calc = MetricsCalculator()
class_metrics = metrics_calc.calculate_classification_metrics(
    y_true=y_frost_test,
    y_pred=y_frost_pred,
    y_proba=y_frost_proba
)

print("ğŸ“Š åˆ†ç±»æ¨¡å‹æ€§èƒ½ (æµ‹è¯•é›†):")
print(f"   ROC-AUC: {class_metrics.get('roc_auc', 'N/A'):.4f}" if 'roc_auc' in class_metrics else "   ROC-AUC: N/A")
print(f"   PR-AUC: {class_metrics.get('pr_auc', 'N/A'):.4f}" if 'pr_auc' in class_metrics else "   PR-AUC: N/A")
print(f"   Brier Score: {class_metrics.get('brier_score', 'N/A'):.4f}" if 'brier_score' in class_metrics else "   Brier Score: N/A")
if 'ece' in class_metrics:
    print(f"   ECE: {class_metrics['ece']:.4f}")
print(f"   Accuracy: {class_metrics.get('accuracy', 'N/A'):.4f}" if 'accuracy' in class_metrics else "   Accuracy: N/A")
print(f"   Precision: {class_metrics.get('precision', 'N/A'):.4f}" if 'precision' in class_metrics else "   Precision: N/A")
print(f"   Recall: {class_metrics.get('recall', 'N/A'):.4f}" if 'recall' in class_metrics else "   Recall: N/A")
print(f"   F1 Score: {class_metrics.get('f1_score', 'N/A'):.4f}" if 'f1_score' in class_metrics else "   F1 Score: N/A")

# Cell 16: Evaluate regression model
print("\n" + "=" * 70)
print("ğŸ“Š Cell 16: è¯„ä¼°å›å½’æ¨¡å‹")
print("=" * 70)

y_temp_pred = temp_model.predict(X_test)

reg_metrics = metrics_calc.calculate_regression_metrics(
    y_true=y_temp_test,
    y_pred=y_temp_pred
)

print("ğŸ“Š å›å½’æ¨¡å‹æ€§èƒ½ (æµ‹è¯•é›†):")
print(f"   MAE: {reg_metrics['mae']:.4f}Â°C")
print(f"   RMSE: {reg_metrics['rmse']:.4f}Â°C")
print(f"   RÂ²: {reg_metrics['r2']:.4f}")
print(f"   MAPE: {reg_metrics.get('mape', 'N/A')}")

# Cell 21: Generate predictions
print("\n" + "=" * 70)
print("ğŸ”® Cell 21: ç”Ÿæˆé¢„æµ‹")
print("=" * 70)

new_data = X_test[:100].copy()

frost_proba_predictions = frost_model.predict_proba(new_data)
temp_predictions = temp_model.predict(new_data)

predictions_df = pd.DataFrame({
    'Frost_Probability': frost_proba_predictions,
    'Temperature_Prediction_C': temp_predictions,
    'Frost_Risk': ['Low' if p < 0.1 else 'Medium' if p < 0.5 else 'High' for p in frost_proba_predictions]
})

print("ğŸ“Š é¢„æµ‹ç»“æœç¤ºä¾‹ (å‰ 20 ä¸ª):")
print(predictions_df.head(20).to_string(index=True))

high_risk = (predictions_df['Frost_Probability'] > 0.5).sum()
print(f"\nâš ï¸  é«˜é£é™©é¢„æµ‹ (æ¦‚ç‡ > 0.5): {high_risk} / {len(predictions_df)} ({high_risk/len(predictions_df)*100:.1f}%)")

print("\n" + "=" * 70)
print("ğŸ‰ Notebook æ•™ç¨‹æ‰§è¡Œå®Œæˆï¼")
print("=" * 70)
print("\nâœ… å·²å®Œæˆ:")
print("   â€¢ æ•°æ®åŠ è½½å’Œæ¢ç´¢")
print("   â€¢ æ•°æ®å¤„ç†ç®¡é“")
print("   â€¢ æ¨¡å‹è®­ç»ƒï¼ˆåˆ†ç±» + å›å½’ï¼‰")
print("   â€¢ æ¨¡å‹è¯„ä¼°")
print("   â€¢ é¢„æµ‹ç”Ÿæˆ")
print("\nğŸ“Š æ¨¡å‹æ€§èƒ½æ€»ç»“:")
print(f"   â€¢ åˆ†ç±» ROC-AUC: {class_metrics['roc_auc']:.4f}")
print(f"   â€¢ å›å½’ RÂ²: {reg_metrics['r2']:.4f}")
print(f"   â€¢ å›å½’ MAE: {reg_metrics['mae']:.4f}Â°C")
print("\n" + "=" * 70)

