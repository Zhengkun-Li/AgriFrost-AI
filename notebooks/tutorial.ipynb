{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AgriFrost-AI æ•™ç¨‹: ç«¯åˆ°ç«¯éœœå†»é¢„æµ‹\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "<img src=\"../docs/logo/AgriFrost-AI-transparent.png\" alt=\"AgriFrost-AI Logo\" width=\"150\"/>\n",
        "\n",
        "## ğŸŒ¡ï¸ AgriFrost-AI å®Œæ•´å·¥ä½œæµæ¼”ç¤º\n",
        "\n",
        "**ä»æ•°æ®åŠ è½½åˆ°æ¨¡å‹è®­ç»ƒå†åˆ°é¢„æµ‹ç”Ÿæˆçš„å®Œæ•´ç¤ºä¾‹**\n",
        "\n",
        "*F3 Innovate Frost Risk Forecasting Challenge (2025)*\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ æœ¬æ•™ç¨‹å†…å®¹\n",
        "\n",
        "æœ¬ Notebook å°†å¸¦æ‚¨å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š\n",
        "\n",
        "1. **ç¯å¢ƒè®¾ç½®å’Œæ•°æ®åŠ è½½**\n",
        "2. **æ•°æ®æ¢ç´¢å’Œå¯è§†åŒ–**\n",
        "3. **ç‰¹å¾å·¥ç¨‹æ¼”ç¤º**\n",
        "4. **æ¨¡å‹è®­ç»ƒï¼ˆLightGBMï¼‰**\n",
        "5. **æ¨¡å‹è¯„ä¼°å’Œå¯è§†åŒ–**\n",
        "6. **ç”Ÿæˆé¢„æµ‹**\n",
        "\n",
        "**é¢„è®¡æ—¶é—´**: ~30-60 åˆ†é’Ÿï¼ˆå–å†³äºæ•°æ®å¤§å°å’Œç¡¬ä»¶ï¼‰\n",
        "\n",
        "**è¦æ±‚**:\n",
        "- Python 3.10+\n",
        "- å·²å®‰è£…é¡¹ç›®ä¾èµ–ï¼ˆ`pip install -r requirements.txt`ï¼‰\n",
        "- æ•°æ®å·²ä¸‹è½½åˆ° `data/raw/frost-risk-forecast-challenge/`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. å¯¼å…¥å¿…è¦çš„åº“\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# è®¾ç½®æ˜¾ç¤ºé€‰é¡¹\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 50)\n",
        "\n",
        "# è®¾ç½®ç»˜å›¾é£æ ¼ï¼ˆå…¼å®¹ä¸åŒç‰ˆæœ¬çš„ matplotlibï¼‰\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8-darkgrid')\n",
        "except OSError:\n",
        "    try:\n",
        "        plt.style.use('seaborn-darkgrid')\n",
        "    except OSError:\n",
        "        plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"âœ… åº“å¯¼å…¥æˆåŠŸï¼\")\n",
        "print(f\"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}\")\n",
        "print(f\"ğŸ Python ç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. æ•°æ®åŠ è½½å’Œæ¢ç´¢\n",
        "\n",
        "é¦–å…ˆï¼Œè®©æˆ‘ä»¬åŠ è½½åŸå§‹æ•°æ®å¹¶æ¢ç´¢å…¶ç»“æ„ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.1 åŠ è½½åŸå§‹æ•°æ®\n",
        "from src.data.loaders import DataLoader\n",
        "\n",
        "data_path = project_root / \"data/raw/frost-risk-forecast-challenge/cimis_all_stations.csv.gz\"\n",
        "\n",
        "if not data_path.exists():\n",
        "    print(f\"âŒ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {data_path}\")\n",
        "    print(\"è¯·å…ˆä¸‹è½½æ•°æ®ï¼ˆå‚è€ƒ docs/QUICK_START.mdï¼‰\")\n",
        "else:\n",
        "    print(f\"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}\")\n",
        "    loader = DataLoader()\n",
        "    df_raw = loader.load_raw_data(data_path)\n",
        "    print(f\"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼\")\n",
        "    print(f\"   å½¢çŠ¶: {df_raw.shape}\")\n",
        "    print(f\"   åˆ—æ•°: {len(df_raw.columns)}\")\n",
        "    print(f\"   æ—¶é—´èŒƒå›´: {df_raw['Date'].min()} åˆ° {df_raw['Date'].max()}\")\n",
        "    print(f\"   ç«™ç‚¹æ•°: {df_raw['Stn Id'].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.2 æŸ¥çœ‹æ•°æ®æ¦‚è§ˆ\n",
        "if 'df_raw' in locals():\n",
        "    print(\"ğŸ“Š æ•°æ®æ¦‚è§ˆ:\")\n",
        "    print(df_raw.head(10))\n",
        "    print(\"\\nğŸ“‹ æ•°æ®ä¿¡æ¯:\")\n",
        "    print(df_raw.info())\n",
        "    print(\"\\nğŸ“ˆ æè¿°æ€§ç»Ÿè®¡:\")\n",
        "    print(df_raw.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. æ•°æ®å¯è§†åŒ–\n",
        "\n",
        "è®©æˆ‘ä»¬å¯è§†åŒ–ä¸€äº›å…³é”®æ¨¡å¼å’Œç‰¹å¾ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.1 æ—¶é—´åºåˆ—å¯è§†åŒ–\n",
        "if 'df_raw' in locals():\n",
        "    # è½¬æ¢æ—¥æœŸåˆ—ä¸º datetime\n",
        "    df_raw['Date'] = pd.to_datetime(df_raw['Date'])\n",
        "    \n",
        "    # é€‰æ‹©å•ä¸ªç«™ç‚¹è¿›è¡Œå¯è§†åŒ–ï¼ˆä¾‹å¦‚ç«™ç‚¹ 2ï¼‰\n",
        "    df_station = df_raw[df_raw['Stn Id'] == 2].copy()\n",
        "    df_station = df_station.sort_values('Date')\n",
        "    \n",
        "    # å–æœ€è¿‘ 1000 è¡Œç”¨äºå¿«é€Ÿå¯è§†åŒ–\n",
        "    df_sample = df_station.tail(1000)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "    \n",
        "    # æ¸©åº¦æ—¶é—´åºåˆ—\n",
        "    axes[0].plot(df_sample['Date'], df_sample['Air Temp (C)'], label='Air Temperature', linewidth=1)\n",
        "    axes[0].axhline(y=0, color='r', linestyle='--', label='Frost Threshold (0Â°C)')\n",
        "    axes[0].set_xlabel('Date')\n",
        "    axes[0].set_ylabel('Temperature (Â°C)')\n",
        "    axes[0].set_title('Air Temperature Time Series (Station 2, Last 1000 Hours)')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # ç›¸å¯¹æ¹¿åº¦æ—¶é—´åºåˆ—\n",
        "    axes[1].plot(df_sample['Date'], df_sample['Rel Hum (%)'], label='Relative Humidity', color='green', linewidth=1)\n",
        "    axes[1].set_xlabel('Date')\n",
        "    axes[1].set_ylabel('Relative Humidity (%)')\n",
        "    axes[1].set_title('Relative Humidity Time Series (Station 2, Last 1000 Hours)')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"ğŸ“Š å¯è§†åŒ–å®Œæˆï¼æ˜¾ç¤ºç«™ç‚¹ 2 æœ€è¿‘ 1000 å°æ—¶çš„æ•°æ®\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.2 éœœå†»äº‹ä»¶ç»Ÿè®¡\n",
        "if 'df_raw' in locals():\n",
        "    # è¯†åˆ«éœœå†»äº‹ä»¶ï¼ˆâ‰¤0Â°Cï¼‰\n",
        "    df_raw['is_frost'] = (df_raw['Air Temp (C)'] <= 0.0).astype(int)\n",
        "    \n",
        "    # æŒ‰æœˆä»½ç»Ÿè®¡éœœå†»äº‹ä»¶\n",
        "    df_raw['Month'] = pd.to_datetime(df_raw['Date']).dt.month\n",
        "    frost_by_month = df_raw.groupby('Month')['is_frost'].agg(['sum', 'count', 'mean'])\n",
        "    frost_by_month.columns = ['Frost Events', 'Total Observations', 'Frost Rate']\n",
        "    \n",
        "    print(\"ğŸ“Š æ¯æœˆéœœå†»äº‹ä»¶ç»Ÿè®¡:\")\n",
        "    print(frost_by_month)\n",
        "    \n",
        "    # å¯è§†åŒ–\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # éœœå†»ç‡æŒ‰æœˆ\n",
        "    axes[0].bar(frost_by_month.index, frost_by_month['Frost Rate'] * 100, color='steelblue')\n",
        "    axes[0].set_xlabel('Month')\n",
        "    axes[0].set_ylabel('Frost Rate (%)')\n",
        "    axes[0].set_title('Frost Rate by Month')\n",
        "    axes[0].set_xticks(range(1, 13))\n",
        "    axes[0].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # éœœå†»äº‹ä»¶æ•°æŒ‰æœˆ\n",
        "    axes[1].bar(frost_by_month.index, frost_by_month['Frost Events'], color='coral')\n",
        "    axes[1].set_xlabel('Month')\n",
        "    axes[1].set_ylabel('Number of Frost Events')\n",
        "    axes[1].set_title('Total Frost Events by Month')\n",
        "    axes[1].set_xticks(range(1, 13))\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nâ„ï¸ æ€»éœœå†»äº‹ä»¶: {df_raw['is_frost'].sum():,}\")\n",
        "    print(f\"ğŸ“Š éœœå†»ç‡: {df_raw['is_frost'].mean()*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. æ•°æ®å¤„ç†ç®¡é“\n",
        "\n",
        "ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®å¤„ç†ç®¡é“æ¥æ¸…æ´—æ•°æ®ã€ç”Ÿæˆç‰¹å¾å’Œæ ‡ç­¾ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 é…ç½®æ•°æ®å¤„ç†ç®¡é“\n",
        "from src.data import DataPipeline\n",
        "\n",
        "# é…ç½®ï¼ˆä½¿ç”¨ Top 175 ç‰¹å¾ï¼‰\n",
        "config = {\n",
        "    \"cleaning\": {\n",
        "        \"config_path\": str(project_root / \"config/data_cleaning.yaml\")\n",
        "    },\n",
        "    \"labels\": {\n",
        "        \"threshold\": 0.0  # éœœå†»é˜ˆå€¼ï¼š0Â°C\n",
        "    },\n",
        "    \"feature_engineering\": {\n",
        "        \"enabled\": True,\n",
        "        \"feature_selection\": {\n",
        "            \"method\": \"top_k\",\n",
        "            \"top_k\": 175  # ä½¿ç”¨ Top 175 ç‰¹å¾\n",
        "        }\n",
        "    },\n",
        "    \"random_state\": 42\n",
        "}\n",
        "\n",
        "print(\"âš™ï¸ é…ç½®æ•°æ®ç®¡é“...\")\n",
        "pipeline = DataPipeline(config=config)\n",
        "print(\"âœ… æ•°æ®ç®¡é“åˆ›å»ºæˆåŠŸï¼\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.2 å¤„ç†æ•°æ®ï¼ˆä½¿ç”¨é‡‡æ ·ä»¥åŠ å¿«æ¼”ç¤ºé€Ÿåº¦ï¼‰\n",
        "if 'data_path' in locals() and data_path.exists():\n",
        "    print(\"ğŸ”„ å¼€å§‹æ•°æ®å¤„ç†...\")\n",
        "    print(\"   âš ï¸  æ³¨æ„ï¼šä¸ºäº†æ¼”ç¤ºé€Ÿåº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨é‡‡æ ·æ•°æ®ï¼ˆ10ä¸‡è¡Œï¼‰\")\n",
        "    print(\"   ğŸ’¡ å®é™…è®­ç»ƒæ—¶å¯ä»¥ç§»é™¤ sample_size å‚æ•°ä½¿ç”¨å…¨éƒ¨æ•°æ®\")\n",
        "    \n",
        "    # å¤„ç†æ•°æ®ï¼ˆä½¿ç”¨é‡‡æ ·ï¼‰\n",
        "    dataset_bundle = pipeline.run(\n",
        "        data_path=data_path,\n",
        "        horizons=[12],  # åªå¤„ç† 12h æ—¶é—´èŒƒå›´\n",
        "        use_feature_engineering=True,\n",
        "        sample_size=100000,  # é‡‡æ · 10 ä¸‡è¡Œç”¨äºæ¼”ç¤º\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    df_processed = dataset_bundle.data\n",
        "    print(f\"âœ… æ•°æ®å¤„ç†å®Œæˆï¼\")\n",
        "    print(f\"   å¤„ç†åå½¢çŠ¶: {df_processed.shape}\")\n",
        "    print(f\"   ç‰¹å¾æ•°: {len(dataset_bundle.feature_columns)}\")\n",
        "    print(f\"   æ ‡ç­¾æ•°: {len(dataset_bundle.label_columns)}\")\n",
        "    \n",
        "    # æ˜¾ç¤ºç‰¹å¾åˆ—\n",
        "    print(f\"\\nğŸ“‹ ç‰¹å¾åˆ—ç¤ºä¾‹ï¼ˆå‰ 20 ä¸ªï¼‰:\")\n",
        "    for i, feat in enumerate(dataset_bundle.feature_columns[:20]):\n",
        "        print(f\"   {i+1}. {feat}\")\n",
        "    if len(dataset_bundle.feature_columns) > 20:\n",
        "        print(f\"   ... (å…± {len(dataset_bundle.feature_columns)} ä¸ªç‰¹å¾)\")\n",
        "else:\n",
        "    print(\"âŒ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè·³è¿‡æ•°æ®å¤„ç†æ­¥éª¤\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. æ¨¡å‹è®­ç»ƒ\n",
        "\n",
        "ç°åœ¨è®©æˆ‘ä»¬è®­ç»ƒä¸€ä¸ª LightGBM æ¨¡å‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 å‡†å¤‡è®­ç»ƒæ•°æ®\n",
        "if 'df_processed' in locals():\n",
        "    from src.training.data_preparation import prepare_features_and_targets\n",
        "    from src.evaluation.validators import CrossValidator\n",
        "    from src.models.registry import get_model_class\n",
        "    \n",
        "    # æ­¥éª¤ 1: æ—¶é—´åºåˆ—åˆ†å‰²ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰\n",
        "    # æ³¨æ„ï¼šå¿…é¡»å…ˆåˆ†å‰²æ•°æ®ï¼Œå†å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾\n",
        "    print(\"ğŸ“Š æ‰§è¡Œæ—¶é—´åºåˆ—åˆ†å‰²...\")\n",
        "    train_df, val_df, test_df = CrossValidator.time_split(\n",
        "        df=df_processed,\n",
        "        train_ratio=0.7,\n",
        "        val_ratio=0.15,\n",
        "        date_col=\"Date\"\n",
        "    )\n",
        "    \n",
        "    print(f\"   è®­ç»ƒé›†: {len(train_df)} æ ·æœ¬\")\n",
        "    print(f\"   éªŒè¯é›†: {len(val_df)} æ ·æœ¬\")\n",
        "    print(f\"   æµ‹è¯•é›†: {len(test_df)} æ ·æœ¬\")\n",
        "    \n",
        "    # æ­¥éª¤ 2: ä¸ºæ¯ä¸ªåˆ†å‰²å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾ï¼ˆ12h æ—¶é—´èŒƒå›´ï¼‰\n",
        "    print(\"\\nğŸ”§ å‡†å¤‡è®­ç»ƒé›†ç‰¹å¾å’Œæ ‡ç­¾...\")\n",
        "    X_train, y_frost_train, y_temp_train = prepare_features_and_targets(\n",
        "        df=train_df,\n",
        "        horizon=12,\n",
        "        track=\"top175_features\"\n",
        "    )\n",
        "    \n",
        "    print(\"ğŸ”§ å‡†å¤‡éªŒè¯é›†ç‰¹å¾å’Œæ ‡ç­¾...\")\n",
        "    X_val, y_frost_val, y_temp_val = prepare_features_and_targets(\n",
        "        df=val_df,\n",
        "        horizon=12,\n",
        "        track=\"top175_features\"\n",
        "    )\n",
        "    \n",
        "    print(\"ğŸ”§ å‡†å¤‡æµ‹è¯•é›†ç‰¹å¾å’Œæ ‡ç­¾...\")\n",
        "    X_test, y_frost_test, y_temp_test = prepare_features_and_targets(\n",
        "        df=test_df,\n",
        "        horizon=12,\n",
        "        track=\"top175_features\"\n",
        "    )\n",
        "    \n",
        "    print(\"\\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼\")\n",
        "    print(f\"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬, {X_train.shape[1]} ç‰¹å¾\")\n",
        "    print(f\"   éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬\")\n",
        "    print(f\"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬\")\n",
        "    print(f\"   éœœå†»äº‹ä»¶ (è®­ç»ƒé›†): {y_frost_train.sum()} ({y_frost_train.mean()*100:.2f}%)\")\n",
        "    print(f\"   å¹³å‡æ¸©åº¦ (è®­ç»ƒé›†): {y_temp_train.mean():.2f}Â°C\")\n",
        "else:\n",
        "    print(\"âŒ è·³è¿‡æ¨¡å‹è®­ç»ƒï¼ˆæ•°æ®æœªå¤„ç†ï¼‰\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.2 è®­ç»ƒåˆ†ç±»æ¨¡å‹ï¼ˆéœœå†»æ¦‚ç‡é¢„æµ‹ï¼‰\n",
        "if 'X_train' in locals():\n",
        "    print(\"ğŸ¤– è®­ç»ƒéœœå†»åˆ†ç±»æ¨¡å‹ (LightGBM)...\")\n",
        "    \n",
        "    # è·å–æ¨¡å‹ç±»\n",
        "    ModelClass = get_model_class('lightgbm')\n",
        "    \n",
        "    # åˆ›å»ºæ¨¡å‹å®ä¾‹\n",
        "    frost_model = ModelClass(\n",
        "        task_type='classification',\n",
        "        model_params={\n",
        "            'n_estimators': 100,  # æ¼”ç¤ºç”¨è¾ƒå°‘æ ‘æ•°ï¼Œå®é™…å¯ä»¥æ›´å¤š\n",
        "            'learning_rate': 0.05,\n",
        "            'max_depth': 7,\n",
        "            'random_state': 42,\n",
        "            'verbosity': -1\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # è®­ç»ƒæ¨¡å‹\n",
        "    frost_model.fit(\n",
        "        X=X_train,\n",
        "        y=y_frost_train,\n",
        "        validation_data=(X_val, y_frost_val)\n",
        "    )\n",
        "    \n",
        "    print(\"âœ… åˆ†ç±»æ¨¡å‹è®­ç»ƒå®Œæˆï¼\")\n",
        "    \n",
        "    # è®­ç»ƒå›å½’æ¨¡å‹ï¼ˆæ¸©åº¦é¢„æµ‹ï¼‰\n",
        "    print(\"ğŸ¤– è®­ç»ƒæ¸©åº¦å›å½’æ¨¡å‹ (LightGBM)...\")\n",
        "    \n",
        "    temp_model = ModelClass(\n",
        "        task_type='regression',\n",
        "        model_params={\n",
        "            'n_estimators': 100,\n",
        "            'learning_rate': 0.05,\n",
        "            'max_depth': 7,\n",
        "            'random_state': 42,\n",
        "            'verbosity': -1\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    temp_model.fit(\n",
        "        X=X_train,\n",
        "        y=y_temp_train,\n",
        "        validation_data=(X_val, y_temp_val)\n",
        "    )\n",
        "    \n",
        "    print(\"âœ… å›å½’æ¨¡å‹è®­ç»ƒå®Œæˆï¼\")\n",
        "else:\n",
        "    print(\"âŒ è·³è¿‡æ¨¡å‹è®­ç»ƒï¼ˆæ•°æ®æœªå‡†å¤‡ï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. æ¨¡å‹è¯„ä¼°å’Œå¯è§†åŒ–\n",
        "\n",
        "è®©æˆ‘ä»¬è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½å¹¶å¯è§†åŒ–ç»“æœã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1 è¯„ä¼°åˆ†ç±»æ¨¡å‹\n",
        "if 'frost_model' in locals():\n",
        "    from src.evaluation.metrics import MetricsCalculator\n",
        "    \n",
        "    # ç”Ÿæˆé¢„æµ‹\n",
        "    y_frost_pred = frost_model.predict(X_test)\n",
        "    y_frost_proba = frost_model.predict_proba(X_test)\n",
        "    \n",
        "    # è®¡ç®—æŒ‡æ ‡\n",
        "    metrics_calc = MetricsCalculator()\n",
        "    class_metrics = metrics_calc.calculate_classification_metrics(\n",
        "        y_true=y_frost_test,\n",
        "        y_pred=y_frost_pred,\n",
        "        y_proba=y_frost_proba\n",
        "    )\n",
        "    \n",
        "    print(\"ğŸ“Š åˆ†ç±»æ¨¡å‹æ€§èƒ½ (æµ‹è¯•é›†):\")\n",
        "    print(f\"   ROC-AUC: {class_metrics['roc_auc']:.4f}\")\n",
        "    print(f\"   PR-AUC: {class_metrics['pr_auc']:.4f}\")\n",
        "    print(f\"   Brier Score: {class_metrics['brier_score']:.4f}\")\n",
        "    print(f\"   ECE: {class_metrics['ece']:.4f}\")\n",
        "    print(f\"   Accuracy: {class_metrics['accuracy']:.4f}\")\n",
        "    print(f\"   Precision: {class_metrics['precision']:.4f}\")\n",
        "    print(f\"   Recall: {class_metrics['recall']:.4f}\")\n",
        "    print(f\"   F1 Score: {class_metrics['f1_score']:.4f}\")\n",
        "else:\n",
        "    print(\"âŒ è·³è¿‡åˆ†ç±»è¯„ä¼°ï¼ˆæ¨¡å‹æœªè®­ç»ƒï¼‰\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.2 è¯„ä¼°å›å½’æ¨¡å‹\n",
        "if 'temp_model' in locals():\n",
        "    # ç”Ÿæˆé¢„æµ‹\n",
        "    y_temp_pred = temp_model.predict(X_test)\n",
        "    \n",
        "    # è®¡ç®—æŒ‡æ ‡\n",
        "    reg_metrics = metrics_calc.calculate_regression_metrics(\n",
        "        y_true=y_temp_test,\n",
        "        y_pred=y_temp_pred\n",
        "    )\n",
        "    \n",
        "    print(\"ğŸ“Š å›å½’æ¨¡å‹æ€§èƒ½ (æµ‹è¯•é›†):\")\n",
        "    print(f\"   MAE: {reg_metrics['mae']:.4f}Â°C\")\n",
        "    print(f\"   RMSE: {reg_metrics['rmse']:.4f}Â°C\")\n",
        "    print(f\"   RÂ²: {reg_metrics['r2']:.4f}\")\n",
        "    print(f\"   MAPE: {reg_metrics.get('mape', 'N/A')}\")\n",
        "else:\n",
        "    print(\"âŒ è·³è¿‡å›å½’è¯„ä¼°ï¼ˆæ¨¡å‹æœªè®­ç»ƒï¼‰\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.3 å¯è§†åŒ–é¢„æµ‹ç»“æœ\n",
        "if 'y_temp_pred' in locals() and 'y_frost_proba' in locals():\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # 1. æ¸©åº¦é¢„æµ‹ vs çœŸå®å€¼\n",
        "    axes[0, 0].scatter(y_temp_test, y_temp_pred, alpha=0.5, s=10)\n",
        "    axes[0, 0].plot([y_temp_test.min(), y_temp_test.max()], \n",
        "                    [y_temp_test.min(), y_temp_test.max()], \n",
        "                    'r--', lw=2, label='Perfect Prediction')\n",
        "    axes[0, 0].set_xlabel('True Temperature (Â°C)')\n",
        "    axes[0, 0].set_ylabel('Predicted Temperature (Â°C)')\n",
        "    axes[0, 0].set_title(f'Temperature Prediction (RÂ² = {reg_metrics[\"r2\"]:.4f})')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. æ¸©åº¦é¢„æµ‹è¯¯å·®åˆ†å¸ƒ\n",
        "    temp_errors = y_temp_pred - y_temp_test\n",
        "    axes[0, 1].hist(temp_errors, bins=50, edgecolor='black', alpha=0.7)\n",
        "    axes[0, 1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
        "    axes[0, 1].set_xlabel('Prediction Error (Â°C)')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "    axes[0, 1].set_title(f'Temperature Prediction Error Distribution (MAE = {reg_metrics[\"mae\"]:.4f}Â°C)')\n",
        "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # 3. ROC æ›²çº¿\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "    fpr, tpr, _ = roc_curve(y_frost_test, y_frost_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    axes[1, 0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    axes[1, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "    axes[1, 0].set_xlabel('False Positive Rate')\n",
        "    axes[1, 0].set_ylabel('True Positive Rate')\n",
        "    axes[1, 0].set_title('ROC Curve for Frost Classification')\n",
        "    axes[1, 0].legend(loc=\"lower right\")\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. éœœå†»æ¦‚ç‡åˆ†å¸ƒ\n",
        "    axes[1, 1].hist(y_frost_proba[y_frost_test == 0], bins=50, alpha=0.7, label='No Frost', color='blue')\n",
        "    axes[1, 1].hist(y_frost_proba[y_frost_test == 1], bins=50, alpha=0.7, label='Frost', color='red')\n",
        "    axes[1, 1].set_xlabel('Predicted Frost Probability')\n",
        "    axes[1, 1].set_ylabel('Frequency')\n",
        "    axes[1, 1].set_title('Frost Probability Distribution')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"âœ… å¯è§†åŒ–å®Œæˆï¼\")\n",
        "else:\n",
        "    print(\"âŒ è·³è¿‡å¯è§†åŒ–ï¼ˆé¢„æµ‹ç»“æœæœªç”Ÿæˆï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ç‰¹å¾é‡è¦æ€§åˆ†æ\n",
        "\n",
        "è®©æˆ‘ä»¬æŸ¥çœ‹å“ªäº›ç‰¹å¾å¯¹æ¨¡å‹æœ€é‡è¦ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.1 è·å–ç‰¹å¾é‡è¦æ€§\n",
        "if 'frost_model' in locals() and 'X_train' in locals():\n",
        "    try:\n",
        "        # è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆä½¿ç”¨ LightGBM booster APIï¼‰\n",
        "        # æ³¨æ„: LightGBM éœ€è¦ä½¿ç”¨ booster_.feature_importance() æ–¹æ³•\n",
        "        feature_importance = frost_model.model.booster_.feature_importance(importance_type='gain')\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': X_train.columns.tolist(),  # ä½¿ç”¨è®­ç»ƒé›†çš„ç‰¹å¾åˆ—\n",
        "            'importance': feature_importance\n",
        "        }).sort_values('importance', ascending=False)\n",
        "        \n",
        "        # æ˜¾ç¤º Top 20 é‡è¦ç‰¹å¾\n",
        "        print(\"ğŸ” Top 20 æœ€é‡è¦ç‰¹å¾:\")\n",
        "        print(importance_df.head(20).to_string(index=False))\n",
        "        \n",
        "        # å¯è§†åŒ– Top 20 ç‰¹å¾é‡è¦æ€§\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        top_features = importance_df.head(20)\n",
        "        ax.barh(range(len(top_features)), top_features['importance'].values, color='steelblue')\n",
        "        ax.set_yticks(range(len(top_features)))\n",
        "        ax.set_yticklabels(top_features['feature'].values)\n",
        "        ax.set_xlabel('Feature Importance (Gain)')\n",
        "        ax.set_title('Top 20 Feature Importance (Frost Classification Model)')\n",
        "        ax.invert_yaxis()  # æœ€é‡è¦çš„åœ¨é¡¶éƒ¨\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  æ— æ³•è·å–ç‰¹å¾é‡è¦æ€§: {e}\")\n",
        "        print(\"   è¿™å¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹ç±»å‹ä¸æ”¯æŒæˆ–æ¨¡å‹æœªæ­£ç¡®åˆå§‹åŒ–\")\n",
        "        print(\"   å°è¯•ä½¿ç”¨ feature_importances_ å±æ€§:\")\n",
        "        try:\n",
        "            # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨ feature_importances_ å±æ€§\n",
        "            feature_importance = frost_model.model.feature_importances_\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': X_train.columns.tolist(),\n",
        "                'importance': feature_importance\n",
        "            }).sort_values('importance', ascending=False)\n",
        "            print(\"\\nâœ… ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æˆåŠŸè·å–ç‰¹å¾é‡è¦æ€§:\")\n",
        "            print(importance_df.head(20).to_string(index=False))\n",
        "        except Exception as e2:\n",
        "            print(f\"   å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}\")\n",
        "else:\n",
        "    print(\"âŒ è·³è¿‡ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆæ¨¡å‹æœªè®­ç»ƒï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ç”Ÿæˆé¢„æµ‹\n",
        "\n",
        "æœ€åï¼Œè®©æˆ‘ä»¬ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆæ–°çš„é¢„æµ‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7.1 å‡†å¤‡æ–°æ•°æ®è¿›è¡Œé¢„æµ‹\n",
        "if 'X_test' in locals() and 'frost_model' in locals():\n",
        "    # ä½¿ç”¨æµ‹è¯•é›†çš„ä¸€éƒ¨åˆ†ä½œä¸ºæ–°æ•°æ®\n",
        "    new_data = X_test[:100].copy()  # å–å‰ 100 ä¸ªæ ·æœ¬\n",
        "    \n",
        "    # ç”Ÿæˆé¢„æµ‹\n",
        "    frost_proba_predictions = frost_model.predict_proba(new_data)\n",
        "    temp_predictions = temp_model.predict(new_data)\n",
        "    \n",
        "    # åˆ›å»ºé¢„æµ‹ç»“æœ DataFrame\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'Frost_Probability': frost_proba_predictions,\n",
        "        'Temperature_Prediction_C': temp_predictions,\n",
        "        'Frost_Risk': ['Low' if p < 0.1 else 'Medium' if p < 0.5 else 'High' for p in frost_proba_predictions]\n",
        "    })\n",
        "    \n",
        "    print(\"ğŸ“Š é¢„æµ‹ç»“æœç¤ºä¾‹ (å‰ 20 ä¸ª):\")\n",
        "    print(predictions_df.head(20).to_string(index=True))\n",
        "    \n",
        "    # ç»Ÿè®¡é«˜é£é™©é¢„æµ‹\n",
        "    high_risk = (predictions_df['Frost_Probability'] > 0.5).sum()\n",
        "    print(f\"\\nâš ï¸  é«˜é£é™©é¢„æµ‹ (æ¦‚ç‡ > 0.5): {high_risk} / {len(predictions_df)} ({high_risk/len(predictions_df)*100:.1f}%)\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ è·³è¿‡é¢„æµ‹ç”Ÿæˆï¼ˆæ¨¡å‹æˆ–æ•°æ®ä¸å¯ç”¨ï¼‰\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7.2 å¯è§†åŒ–é¢„æµ‹ç»“æœ\n",
        "if 'predictions_df' in locals():\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # éœœå†»æ¦‚ç‡åˆ†å¸ƒ\n",
        "    axes[0].hist(predictions_df['Frost_Probability'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "    axes[0].axvline(x=0.5, color='r', linestyle='--', linewidth=2, label='High Risk Threshold (0.5)')\n",
        "    axes[0].set_xlabel('Frost Probability')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    axes[0].set_title('Distribution of Frost Probability Predictions')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # æ¸©åº¦é¢„æµ‹åˆ†å¸ƒ\n",
        "    axes[1].hist(predictions_df['Temperature_Prediction_C'], bins=30, edgecolor='black', alpha=0.7, color='coral')\n",
        "    axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2, label='Frost Threshold (0Â°C)')\n",
        "    axes[1].set_xlabel('Predicted Temperature (Â°C)')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    axes[1].set_title('Distribution of Temperature Predictions')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"âœ… é¢„æµ‹å¯è§†åŒ–å®Œæˆï¼\")\n",
        "else:\n",
        "    print(\"âŒ è·³è¿‡å¯è§†åŒ–ï¼ˆé¢„æµ‹ç»“æœä¸å¯ç”¨ï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. æ€»ç»“å’Œä¸‹ä¸€æ­¥\n",
        "\n",
        "æ­å–œï¼æ‚¨å·²ç»å®Œæˆäº† AgriFrost-AI çš„å®Œæ•´å·¥ä½œæµç¨‹æ¼”ç¤ºï¼\n",
        "\n",
        "### ğŸ“‹ æœ¬æ•™ç¨‹æ€»ç»“\n",
        "\n",
        "âœ… **å·²å®Œæˆ**:\n",
        "1. æ•°æ®åŠ è½½å’Œæ¢ç´¢\n",
        "2. æ•°æ®å¯è§†åŒ–å’Œç»Ÿè®¡åˆ†æ\n",
        "3. æ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹\n",
        "4. æ¨¡å‹è®­ç»ƒï¼ˆåˆ†ç±»å’Œå›å½’ï¼‰\n",
        "5. æ¨¡å‹è¯„ä¼°å’Œæ€§èƒ½åˆ†æ\n",
        "6. ç‰¹å¾é‡è¦æ€§åˆ†æ\n",
        "7. é¢„æµ‹ç”Ÿæˆå’Œå¯è§†åŒ–\n",
        "\n",
        "### ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®\n",
        "\n",
        "1. **å°è¯•ä¸åŒæ¨¡å‹**:\n",
        "   - XGBoost: `get_model_class('xgboost')`\n",
        "   - CatBoost: `get_model_class('catboost')`\n",
        "   - LSTM: `get_model_class('lstm')` (éœ€è¦ GPU)\n",
        "\n",
        "2. **å°è¯•ä¸åŒæ—¶é—´èŒƒå›´**:\n",
        "   - ä¿®æ”¹ `horizons=[3, 6, 12, 24]` è®­ç»ƒå¤šä¸ªæ—¶é—´èŒƒå›´\n",
        "\n",
        "3. **å°è¯•ä¸åŒç‰¹å¾é›†**:\n",
        "   - å®Œæ•´ç‰¹å¾é›†ï¼ˆ298 ç‰¹å¾ï¼‰\n",
        "   - è‡ªå®šä¹‰ç‰¹å¾é€‰æ‹©\n",
        "\n",
        "4. **ç©ºé—´èšåˆ**:\n",
        "   - å°è¯• Matrix Cell C/Dï¼ˆå¤šç«™ç‚¹ç‰¹å¾ï¼‰\n",
        "   - å°è¯• Matrix Cell Eï¼ˆå›¾ç¥ç»ç½‘ç»œï¼‰\n",
        "\n",
        "5. **æ¨¡å‹è°ƒä¼˜**:\n",
        "   - ä½¿ç”¨è¶…å‚æ•°ä¼˜åŒ–\n",
        "   - å°è¯•ä¸åŒçš„æ¨¡å‹é…ç½®\n",
        "\n",
        "### ğŸ“š æ·±å…¥å­¦ä¹ \n",
        "\n",
        "- ğŸ“– **å¿«é€Ÿå¼€å§‹**: `docs/QUICK_START.md`\n",
        "- ğŸ—ï¸ **å®ç°æŒ‡å—**: `docs/IMPLEMENTATION_GUIDE.md` / `docs/IMPLEMENTATION_GUIDE_CN.md`\n",
        "- ğŸ”¬ **æŠ€æœ¯æ–‡æ¡£**: `docs/TECHNICAL_DOCUMENTATION.md`\n",
        "- ğŸ¤– **æ¨¡å‹æŒ‡å—**: `docs/MODELS_GUIDE.md`\n",
        "- ğŸ“Š **ç‰¹å¾æŒ‡å—**: `docs/FEATURE_GUIDE.md`\n",
        "\n",
        "### ğŸ’¡ æç¤º\n",
        "\n",
        "- ä½¿ç”¨å®Œæ•´æ•°æ®é›†å¯ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼ˆç§»é™¤ `sample_size` å‚æ•°ï¼‰\n",
        "- å¢åŠ  `n_estimators` å¯ä»¥æé«˜æ¨¡å‹å‡†ç¡®åº¦ï¼ˆä½†è®­ç»ƒæ—¶é—´æ›´é•¿ï¼‰\n",
        "- ä½¿ç”¨ GPU å¯ä»¥åŠ é€Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ\n",
        "- LOSO è¯„ä¼°å¯ä»¥æµ‹è¯•æ¨¡å‹çš„ç©ºé—´æ³›åŒ–èƒ½åŠ›\n",
        "\n",
        "---\n",
        "\n",
        "**æ„Ÿè°¢ä½¿ç”¨ AgriFrost-AIï¼** ğŸŒ¡ï¸ğŸ¤–\n",
        "\n",
        "**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  \n",
        "**æœ€åæ›´æ–°**: 2025-11-19  \n",
        "**ä½œè€…**: Zhengkun LI (TRIC Robotics / UF ABE)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
